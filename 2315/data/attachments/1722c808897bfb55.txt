[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  shard-two/0 [idle] active: Shard drained from cluster, ready for removal
  shard-two/1 [idle] active: Primary
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  shard-two/0 [idle] maintenance: Adding shard to config-server
  shard-two/1 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  shard-two/0 [idle] maintenance: Adding shard to config-server
  shard-two/1 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  shard-two/0 [idle] maintenance: Adding shard to config-server
  shard-two/1 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  shard-two/0 [idle] active: 
  shard-two/1 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  shard-two/0 [idle] active: 
  shard-two/1 [idle] active: Primary
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  shard-two/0 [idle] active: 
  shard-two/1 [idle] active: Primary
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
  config-server-one/1 [idle] active: 
  shard-one/0 [idle] active: 
  shard-one/1 [idle] active: Primary
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
  config-server-one/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
  config-server-one/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
  config-server-one/1 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
  config-server-one/1 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
  config-server-one/1 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
  config-server-one/1 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] active: Primary
  config-server-one/1 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] active: Primary
  config-server-one/1 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] active: Primary
  config-server-one/1 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] active: Primary
  config-server-one/1 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server-one/0 [idle] active: Primary
  config-server-one/1 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m pytest_operator.plugin:plugin.py:834 Model status:

Model  Controller          Cloud/Region        Version  SLA          Timestamp
test   microk8s-localhost  microk8s/localhost  3.5.3    unsupported  02:12:04Z

App                Version  Status  Scale  Charm        Channel  Rev  Address         Exposed  Message
config-server-one           active      2  mongodb-k8s             0  10.152.183.24   no       
shard-one                   active      2  mongodb-k8s             1  10.152.183.66   no       
shard-three                 active      2  mongodb-k8s             3  10.152.183.125  no       

Unit                  Workload  Agent  Address       Ports  Message
config-server-one/0*  active    idle   10.1.134.204         
config-server-one/1   active    idle   10.1.134.205         
shard-one/0*          active    idle   10.1.134.210         
shard-one/1           active    idle   10.1.134.211         Primary
shard-three/0         active    idle   10.1.134.222         
shard-three/1*        active    idle   10.1.134.223         Primary

[32mINFO    [0m pytest_operator.plugin:plugin.py:840 Juju error logs:

unit-config-server-one-0: 01:38:24 ERROR unit.config-server-one/0.juju-log database-peers:0: Failed to create the operator user: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-config-server-one-0/charm/./src/charm.py", line 939, in _init_operator_user
    process.wait_output()
  File "/var/lib/juju/agents/unit-config-server-one-0/charm/venv/ops/pebble.py", line 1773, in wait_output
    raise ExecError[AnyStr](self._command, exit_code, out_value, err_value)
ops.pebble.ExecError: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
unit-config-server-one-0: 01:38:30 ERROR unit.config-server-one/0.juju-log database-peers:0: Failed to create the operator user: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-config-server-one-0/charm/./src/charm.py", line 939, in _init_operator_user
    process.wait_output()
  File "/var/lib/juju/agents/unit-config-server-one-0/charm/venv/ops/pebble.py", line 1773, in wait_output
    raise ExecError[AnyStr](self._command, exit_code, out_value, err_value)
ops.pebble.ExecError: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
unit-config-server-one-0: 01:40:53 ERROR unit.config-server-one/0.juju-log config-server:5: Failed to add shard shard-two to the config server, error=OperationFailure("Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed', '$clusterTime': {'clusterTime': Timestamp(1725673252, 2), 'signature': {'hash': b'\\xde\\x1f\\x94\\xbc\\x1b@\\xb62g\\xf8\\xe4Y\\xe4|\\xce\\xb4,\\xa0\\xc61', 'keyId': 7411709588216479755}}, 'operationTime': Timestamp(1725673252, 2)}")
unit-config-server-one-0: 01:40:54 ERROR unit.config-server-one/0.juju-log config-server:5: shard-two shard does not have the same auth as the config server.
unit-config-server-one-0: 01:41:10 ERROR unit.config-server-one/0.juju-log config-server:5: Failed to add shard shard-two to the config server, error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-two, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-two\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1725673269, 1), \'signature\': {\'hash\': b"\\xf1\\xda\\xb8\\xb1\\xde`h\\x12\'l\\xbf\\xf2\\xb1\\x12;OG0a ", \'keyId\': 7411709588216479755}}, \'operationTime\': Timestamp(1725673269, 1)}')
unit-config-server-one-0: 01:41:10 ERROR unit.config-server-one/0.juju-log config-server:5: Failed to add shard-two to cluster
unit-config-server-one-0: 01:41:10 ERROR unit.config-server-one/0.juju-log config-server:5: Deferring _on_relation_event for shards interface since: error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-two, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-two\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1725673269, 1), \'signature\': {\'hash\': b"\\xf1\\xda\\xb8\\xb1\\xde`h\\x12\'l\\xbf\\xf2\\xb1\\x12;OG0a ", \'keyId\': 7411709588216479755}}, \'operationTime\': Timestamp(1725673269, 1)}')
unit-config-server-one-0: 01:41:31 ERROR unit.config-server-one/0.juju-log config-server:4: Failed to add shard shard-three to the config server, error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-three, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-three\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1725673290, 3), \'signature\': {\'hash\': b\'\\x89=\\xa6b\\xb4[[\\xc5\\xf5p\\xab\\xf9\\xf4\\x1aF\\xd9\\x00+-\\xcc\', \'keyId\': 7411709588216479755}}, \'operationTime\': Timestamp(1725673290, 3)}')
unit-config-server-one-0: 01:41:35 ERROR unit.config-server-one/0.juju-log config-server:4: Failed to add shard-three to cluster
unit-config-server-one-0: 01:41:35 ERROR unit.config-server-one/0.juju-log config-server:4: Deferring _on_relation_event for shards interface since: error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-three, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-three\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1725673290, 3), \'signature\': {\'hash\': b\'\\x89=\\xa6b\\xb4[[\\xc5\\xf5p\\xab\\xf9\\xf4\\x1aF\\xd9\\x00+-\\xcc\', \'keyId\': 7411709588216479755}}, \'operationTime\': Timestamp(1725673290, 3)}')
unit-shard-three-1: 01:49:56 ERROR juju.worker.dependency "uniter" manifold worker returned unexpected error: relation scope id "1092f421-e991-4157-8282-1c51ca9907a8:r#6#config-server-one": settings 1092f421-e991-4157-8282-1c51ca9907a8:r#6#config-server-one not found (not found)
unit-shard-two-1: 02:05:23 ERROR unit.shard-two/1.juju-log shard-two/1.is_unit_in_replica_set PyMongoError=No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 66dbb4e22f65e457aa50a999, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('shard-two-1.shard-two-endpoints', 27017) server_type: RSGhost, rtt: 0.000500419999980295>]>

[32mINFO    [0m pytest_operator.plugin:plugin.py:904 Forgetting main...