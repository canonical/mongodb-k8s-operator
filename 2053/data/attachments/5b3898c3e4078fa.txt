[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] active: 
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] active: Primary
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-12T01:49:29Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2958 Waiting for model:
  config-server/0 [idle] active: Primary
  config-server/1 [idle] active:
[32mINFO    [0m pytest_operator.plugin:plugin.py:834 Model status:

Model  Controller          Cloud/Region        Version  SLA          Timestamp
test   microk8s-localhost  microk8s/localhost  3.4.4    unsupported  01:58:06Z

App            Version  Status   Scale  Charm          Channel      Rev  Address         Exposed  Message
application             waiting      1  application                   0  10.152.183.27   no       installing agent
config-server           active       2  mongodb-k8s                   0  10.152.183.254  no       Primary
s3-integrator           active       1  s3-integrator  latest/edge   31  10.152.183.69   no       
shard-one               active       2  mongodb-k8s                   1  10.152.183.180  no       Primary
shard-two               active       1  mongodb-k8s                   2  10.152.183.91   no       Primary

Unit              Workload  Agent  Address       Ports  Message
application/0*    waiting   idle   10.1.242.200         
config-server/0*  active    idle   10.1.242.205         Primary
config-server/1   active    idle   10.1.242.206         
s3-integrator/0*  active    idle   10.1.242.215         
shard-one/0*      active    idle   10.1.242.211         Primary
shard-one/1       active    idle   10.1.242.214         
shard-two/0*      active    idle   10.1.242.216         Primary

[32mINFO    [0m pytest_operator.plugin:plugin.py:840 Juju error logs:

unit-config-server-0: 01:38:32 ERROR unit.config-server/0.juju-log Failed to create the operator user: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-config-server-0/charm/./src/charm.py", line 911, in _init_operator_user
    process.wait_output()
  File "/var/lib/juju/agents/unit-config-server-0/charm/venv/ops/pebble.py", line 1771, in wait_output
    raise ExecError[AnyStr](self._command, exit_code, out_value, err_value)
ops.pebble.ExecError: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
unit-config-server-0: 01:38:37 ERROR unit.config-server/0.juju-log Failed to create the operator user: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-config-server-0/charm/./src/charm.py", line 911, in _init_operator_user
    process.wait_output()
  File "/var/lib/juju/agents/unit-config-server-0/charm/venv/ops/pebble.py", line 1771, in wait_output
    raise ExecError[AnyStr](self._command, exit_code, out_value, err_value)
ops.pebble.ExecError: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
unit-config-server-0: 01:39:50 ERROR unit.config-server/0.juju-log config-server:7: Failed to get pbm status: non-zero exit code 1 executing ['/usr/bin/pbm', 'status', '-o', 'json'], stdout='{"Error":"get status of pitr: unable check PITR config status: get config: missed config"}\n', stderr=''
unit-config-server-0: 01:39:51 ERROR unit.config-server/0.juju-log config-server:7: Failed to get pbm status: non-zero exit code 1 executing ['/usr/bin/pbm', 'status', '-o', 'json'], stdout='{"Error":"get status of pitr: unable check PITR config status: get config: missed config"}\n', stderr=''
unit-config-server-0: 01:39:53 ERROR unit.config-server/0.juju-log config-server:7: Failed to get pbm status: non-zero exit code 1 executing ['/usr/bin/pbm', 'status', '-o', 'json'], stdout='{"Error":"get status of pitr: unable check PITR config status: get config: missed config"}\n', stderr=''
unit-config-server-0: 01:40:07 ERROR unit.config-server/0.juju-log config-server:7: Failed to add shard shard-one to the config server, error=OperationFailure("Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed', '$clusterTime': {'clusterTime': Timestamp(1723426807, 1), 'signature': {'hash': b'R\\xb7\\x06?\\x9f\\x0e\\xfe\\xac\\xda\\xaa\\r\\xbfO*uA\\x0e\\xc1$f', 'keyId': 7402061412337451018}}, 'operationTime': Timestamp(1723426807, 1)}")
unit-config-server-0: 01:40:07 ERROR unit.config-server/0.juju-log config-server:7: shard-one shard does not have the same auth as the config server.
unit-config-server-0: 01:40:23 ERROR unit.config-server/0.juju-log config-server:6: Failed to add shard shard-one to the config server, error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1723426823, 1), \'signature\': {\'hash\': b\'\\xa1\\xf3\\xb1\\xb4%#P/\\xd2\\xe1\\xbc\\x07.,\\xf7q\\xb4\\x95\\xf1\\xe0\', \'keyId\': 7402061412337451018}}, \'operationTime\': Timestamp(1723426823, 1)}')
unit-config-server-0: 01:40:23 ERROR unit.config-server/0.juju-log config-server:6: Failed to add shard-one to cluster
unit-config-server-0: 01:40:23 ERROR unit.config-server/0.juju-log config-server:6: Deferring _on_relation_event for shards interface since: error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1723426823, 1), \'signature\': {\'hash\': b\'\\xa1\\xf3\\xb1\\xb4%#P/\\xd2\\xe1\\xbc\\x07.,\\xf7q\\xb4\\x95\\xf1\\xe0\', \'keyId\': 7402061412337451018}}, \'operationTime\': Timestamp(1723426823, 1)}')
unit-config-server-0: 01:40:26 ERROR unit.config-server/0.juju-log config-server:6: Failed to get pbm status: non-zero exit code 1 executing ['/usr/bin/pbm', 'status', '-o', 'json'], stdout='{"Error":"get status of cluster: connect to `shard-one` [shard-one/shard-one-0.shard-one-endpoints:27017,shard-one-1.shard-one-endpoints:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \\"SCRAM-SHA-256\\": (AuthenticationFailed) Authentication failed."}\n', stderr=''
unit-config-server-0: 01:40:27 ERROR unit.config-server/0.juju-log config-server:6: Failed to get pbm status: non-zero exit code 1 executing ['/usr/bin/pbm', 'status', '-o', 'json'], stdout='{"Error":"get status of cluster: connect to `shard-one` [shard-one/shard-one-0.shard-one-endpoints:27017,shard-one-1.shard-one-endpoints:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \\"SCRAM-SHA-256\\": (AuthenticationFailed) Authentication failed."}\n', stderr=''
unit-shard-one-0: 01:44:46 ERROR unit.shard-one/0.juju-log Backup failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:44:47 ERROR unit.shard-one/0.juju-log List-backups failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:44:48 ERROR unit.shard-one/0.juju-log Restore failed: Relation with s3-integrator charm missing, cannot restore from a backup.

[32mINFO    [0m pytest_operator.plugin:plugin.py:904 Forgetting main...