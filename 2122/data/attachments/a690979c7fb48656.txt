[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] active: 
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] active: Primary
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] maintenance: restore started/running, backup id:'2024-08-17T01:46:01Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2972 Waiting for model:
  config-server/0 [idle] active: Primary
  config-server/1 [idle] active:
[32mINFO    [0m pytest_operator.plugin:plugin.py:834 Model status:

Model  Controller          Cloud/Region        Version  SLA          Timestamp
test   microk8s-localhost  microk8s/localhost  3.4.4    unsupported  01:54:28Z

App            Version  Status   Scale  Charm          Channel      Rev  Address         Exposed  Message
application             waiting      1  application                   0  10.152.183.244  no       installing agent
config-server           active       2  mongodb-k8s                   0  10.152.183.123  no       Primary
s3-integrator           active       1  s3-integrator  latest/edge   35  10.152.183.119  no       
shard-one               active       2  mongodb-k8s                   1  10.152.183.196  no       Primary
shard-two               active       1  mongodb-k8s                   2  10.152.183.19   no       Primary

Unit              Workload  Agent  Address      Ports  Message
application/0*    waiting   idle   10.1.255.72         
config-server/0*  active    idle   10.1.255.77         Primary
config-server/1   active    idle   10.1.255.78         
s3-integrator/0*  active    idle   10.1.255.87         
shard-one/0*      active    idle   10.1.255.83         Primary
shard-one/1       active    idle   10.1.255.84         
shard-two/0*      active    idle   10.1.255.88         Primary

[32mINFO    [0m pytest_operator.plugin:plugin.py:840 Juju error logs:

unit-config-server-0: 01:34:47 ERROR unit.config-server/0.juju-log database-peers:1: Failed to create the operator user: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-config-server-0/charm/./src/charm.py", line 926, in _init_operator_user
    process.wait_output()
  File "/var/lib/juju/agents/unit-config-server-0/charm/venv/ops/pebble.py", line 1771, in wait_output
    raise ExecError[AnyStr](self._command, exit_code, out_value, err_value)
ops.pebble.ExecError: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
unit-config-server-0: 01:34:53 ERROR unit.config-server/0.juju-log database-peers:1: Failed to create the operator user: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-config-server-0/charm/./src/charm.py", line 926, in _init_operator_user
    process.wait_output()
  File "/var/lib/juju/agents/unit-config-server-0/charm/venv/ops/pebble.py", line 1771, in wait_output
    raise ExecError[AnyStr](self._command, exit_code, out_value, err_value)
ops.pebble.ExecError: non-zero exit code 1 executing ['/usr/bin/mongosh', 'mongodb://localhost/admin', '--quiet', '--eval', "db.createUser({  user: 'operator',  pwd: passwordPrompt(),  roles:[    {'role': 'userAdminAnyDatabase', 'db': 'admin'},     {'role': 'readWriteAnyDatabase', 'db': 'admin'},     {'role': 'clusterAdmin', 'db': 'admin'},   ],  mechanisms: ['SCRAM-SHA-256'],  passwordDigestor: 'server',})"], stdout='Enter password\n********************************', stderr='MongoServerError: not primary\n'
unit-config-server-0: 01:36:01 ERROR unit.config-server/0.juju-log config-server:7: Failed to get pbm status: non-zero exit code 1 executing ['/usr/bin/pbm', 'status', '-o', 'json'], stdout='{"Error":"get status of pitr: unable check PITR config status: get config: missed config"}\n', stderr=''
unit-config-server-0: 01:36:03 ERROR unit.config-server/0.juju-log config-server:6: Failed to get pbm status: non-zero exit code 1 executing ['/usr/bin/pbm', 'status', '-o', 'json'], stdout='{"Error":"get status of pitr: unable check PITR config status: get config: missed config"}\n', stderr=''
unit-config-server-0: 01:36:11 ERROR unit.config-server/0.juju-log config-server:6: Failed to add shard shard-one to the config server, error=OperationFailure("Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed', '$clusterTime': {'clusterTime': Timestamp(1723858570, 1), 'signature': {'hash': b'r\\xc5=\\xb1\\xdet\\xc0\\xc8\\xb6HGHuPM\\xb4\\x1d\\x97\\x19\\xb9', 'keyId': 7403915867546714136}}, 'operationTime': Timestamp(1723858570, 1)}")
unit-config-server-0: 01:36:11 ERROR unit.config-server/0.juju-log config-server:6: shard-one shard does not have the same auth as the config server.
unit-config-server-0: 01:36:27 ERROR unit.config-server/0.juju-log config-server:6: Failed to add shard shard-one to the config server, error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1723858586, 1), \'signature\': {\'hash\': b\'\\x9c\\xed\\x0fo\\xd9\\xdb\\xbb\\xe8&\\xd4\\xf4\\n#\\xd3\\r\\xf3\\xc2\\xa1\\x89\\xf4\', \'keyId\': 7403915867546714136}}, \'operationTime\': Timestamp(1723858586, 1)}')
unit-config-server-0: 01:36:27 ERROR unit.config-server/0.juju-log config-server:6: Failed to add shard-one to cluster
unit-config-server-0: 01:36:27 ERROR unit.config-server/0.juju-log config-server:6: Deferring _on_relation_event for shards interface since: error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1723858586, 1), \'signature\': {\'hash\': b\'\\x9c\\xed\\x0fo\\xd9\\xdb\\xbb\\xe8&\\xd4\\xf4\\n#\\xd3\\r\\xf3\\xc2\\xa1\\x89\\xf4\', \'keyId\': 7403915867546714136}}, \'operationTime\': Timestamp(1723858586, 1)}')
unit-config-server-0: 01:36:30 ERROR unit.config-server/0.juju-log config-server:6: Failed to get pbm status: non-zero exit code 1 executing ['/usr/bin/pbm', 'status', '-o', 'json'], stdout='{"Error":"get status of cluster: connect to `shard-one` [shard-one/shard-one-0.shard-one-endpoints:27017,shard-one-1.shard-one-endpoints:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \\"SCRAM-SHA-256\\": (AuthenticationFailed) Authentication failed."}\n', stderr=''
unit-config-server-0: 01:36:37 ERROR unit.config-server/0.juju-log config-server:7: Failed to add shard shard-two to the config server, error=OperationFailure("Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed', '$clusterTime': {'clusterTime': Timestamp(1723858597, 1), 'signature': {'hash': b'4\\xed\\x92P\\x88\\x94\\x12>\\xfa\\xdd;d\\x90y\\xe1&\\xb7\\x17\\x03\\xed', 'keyId': 7403915867546714136}}, 'operationTime': Timestamp(1723858597, 1)}")
unit-config-server-0: 01:36:37 ERROR unit.config-server/0.juju-log config-server:7: shard-two shard does not have the same auth as the config server.
unit-shard-one-0: 01:41:07 ERROR unit.shard-one/0.juju-log Backup failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:41:08 ERROR unit.shard-one/0.juju-log List-backups failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:41:09 ERROR unit.shard-one/0.juju-log Restore failed: Relation with s3-integrator charm missing, cannot restore from a backup.

[32mINFO    [0m pytest_operator.plugin:plugin.py:904 Forgetting main...